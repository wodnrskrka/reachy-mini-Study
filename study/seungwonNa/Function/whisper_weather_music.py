import os
import sys
import tempfile
import requests
import speech_recognition as sr
import contextlib
from gtts import gTTS
import pygame
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
import noisereduce as nr
import soundfile as sf
import torch

# ========== ì„¤ì • ==========
USE_GPU = torch.cuda.is_available()
DEVICE = 0 if USE_GPU else -1
WAKE_WORDS = ["í—¬ë¡œ", "hi", "í•˜ì´", "ì•ˆë…•"]
EXIT_WORDS = ["ì—†ì–´", "ëì–´", "ì•„ë‹ˆ"]
MUSIC_PATH = "/home/naseungwon/reachy_mini/no-copyright-music-1.mp3"

# ========== ì´ˆê¸°í™” ==========
pygame.mixer.init()

print("ğŸ§  Whisper-large-v3 ëª¨ë¸ ë¡œë”© ì¤‘...")
stt_pipeline = pipeline("automatic-speech-recognition", model="openai/whisper-large-v3", device=DEVICE)

model_id = "google/flan-t5-base"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForSeq2SeqLM.from_pretrained(model_id)
llm = pipeline("text2text-generation", model=model, tokenizer=tokenizer)

# ========== ìœ í‹¸ í•¨ìˆ˜ ==========
def suppress_stderr_globally():
    sys.stderr = open(os.devnull, 'w')

@contextlib.contextmanager
def suppress_stderr():
    with open(os.devnull, 'w') as fnull:
        stderr = sys.stderr
        sys.stderr = fnull
        try:
            yield
        finally:
            sys.stderr = stderr

# ========== ìŒì„± ì…ë ¥ ==========
def listen_audio(timeout=10, phrase_time_limit=5, filename="input.wav"):
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("ğŸ¤ ìŒì„±ì„ ë“£ê³  ìˆì–´ìš”...")
        with suppress_stderr():
            audio = recognizer.listen(source, timeout=timeout, phrase_time_limit=phrase_time_limit)
            with open(filename, "wb") as f:
                f.write(audio.get_wav_data())
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {filename}")
    return filename

def clean_audio(input_path="input.wav", output_path="cleaned.wav"):
    try:
        data, rate = sf.read(input_path)
        reduced = nr.reduce_noise(y=data, sr=rate)
        sf.write(output_path, reduced, rate)
        print(f"ğŸ”‡ ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ â†’ {output_path}")
        return output_path
    except Exception as e:
        print("âŒ ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨:", e)
        return input_path

def transcribe_audio(filename="cleaned.wav"):
    result = stt_pipeline(filename)
    print("ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", result['text'])
    return result['text'].strip()

# ========== í…ìŠ¤íŠ¸ ì‘ë‹µ ìƒì„± ==========
def generate_response(text):
    prompt = f"ì§ˆë¬¸: {text.strip()}\nëŒ€ë‹µ:"
    result = llm(prompt, max_new_tokens=100)
    response = result[0]["generated_text"].strip()
    return response if response else "ì£„ì†¡í•´ìš”, ì˜ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”."

# ========== ìŒì„± ì¶œë ¥ ==========
def speak(text, lang='ko'):
    if not text.strip():
        print("âš ï¸ ìŒì„±ìœ¼ë¡œ ì¶œë ¥í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    print(f"ğŸ—£ ì‘ë‹µ: {text}")
    tts = gTTS(text=text, lang=lang)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        tts.save(fp.name)
        pygame.mixer.music.load(fp.name)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pass

# ========== ìŒì•… ì¬ìƒ ==========
music_state = "stopped"  # ìƒíƒœ: "playing", "paused", "stopped"

def play_music():
    if os.path.exists(MUSIC_PATH):
        pygame.mixer.music.load(MUSIC_PATH)
        pygame.mixer.music.play()
        print("ğŸµ ìŒì•… ì¬ìƒ ì¤‘...")
    else:
        speak("ì£„ì†¡í•´ìš”, ìŒì•… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.")

def stop_music():
    if pygame.mixer.music.get_busy():
        pygame.mixer.music.stop()
        print("â¹ ìŒì•… êº¼ì§")

def speak_nonblocking(text, lang='ko'):
    tts = gTTS(text=text, lang=lang)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        tts.save(fp.name)
        sound = pygame.mixer.Sound(fp.name)
        ch = pygame.mixer.find_channel()
        if ch:
            ch.play(sound)

# ========== ë‚ ì”¨ ì •ë³´ ==========
def get_weather(city="Seoul"):
    API_KEY = "5d17af980c9cf48721b0e57c1b4fedaf"
    url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_KEY}&lang=kr&units=metric"
    res = requests.get(url)
    if res.status_code == 200:
        data = res.json()
        desc = data["weather"][0]["description"]
        temp = data["main"]["temp"]
        return f"{city}ì˜ í˜„ì¬ ë‚ ì”¨ëŠ” {desc}, ê¸°ì˜¨ì€ {temp:.1f}ë„ì…ë‹ˆë‹¤."
    else:
        return "ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”."

# ========== ë©”ì¸ ë£¨í”„ ==========
def main():
    suppress_stderr_globally()
    print("ğŸ¤– 'í—¬ë¡œ ë¯¸ë‹ˆ'ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì…ë‹ˆë‹¤...")

    # [1] ì›¨ì´í¬ ì›Œë“œ ëŒ€ê¸°
    while True:
        path = listen_audio()
        cleaned = clean_audio(path)
        transcript = transcribe_audio(cleaned).lower()
        if any(transcript.startswith(wake) or transcript == wake for wake in WAKE_WORDS):
            speak("ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
            break

    # [2] ëª…ë ¹ ì²˜ë¦¬ ë£¨í”„ (ì§€ì†ì ìœ¼ë¡œ ëª…ë ¹ ìˆ˜ìš©)
    while True:
        path = listen_audio()
        cleaned = clean_audio(path)
        user_text = transcribe_audio(cleaned).lower()

        if any(bye in user_text for bye in EXIT_WORDS):
            speak("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ëª…ë ¹ ì²˜ë¦¬
        if "ë‚ ì”¨" in user_text:
            response = get_weather()
            speak(response)

        elif "ìŒì•…" in user_text or "ë…¸ë˜" in user_text:
            speak("ìŒì•…ì„ ì¬ìƒí• ê²Œìš”.")
            play_music()

            # ìŒì•… ì¬ìƒ ì¤‘ ë©ˆì¶¤ ê°ì§€ ë£¨í”„
            while True:
                path = listen_audio()
                cleaned = clean_audio(path)
                cmd = transcribe_audio(cleaned).lower()
                if "êº¼ì¤˜" in cmd:
                    stop_music()
                    speak("ìŒì•…ì„ ëŒê²Œìš”.")
                    break
                else:
                    speak_nonblocking("ì£„ì†¡í•´ìš”, ì˜ ëª» ì•Œì•„ ë“¤ì—ˆì–´ìš”.")
                    # ìŒì•… ê³„ì† ìœ ì§€ (ì¤‘ë‹¨ ì•ˆ ë¨!)

        else:
            response = generate_response(user_text)
            speak(response)

        # ë‹¤ìŒ ì§ˆë¬¸ ìœ ë„
        speak("ë” í•„ìš”í•œ ê±° ìˆìœ¼ì‹ ê°€ìš”?")


if __name__ == "__main__":
    main()
